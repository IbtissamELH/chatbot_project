# backend/chatbot_engine_bert.py
import pandas as pd
from sentence_transformers import SentenceTransformer, util

# ðŸ”¹ Dictionnaire de rÃ©ponses simples
SALUTATIONS = {
    "bonjour": "Bonjour ðŸ˜Š ! Je suis ChatMI. Pose-moi une question sur une anomalie ou une panne.",
    "salut": "Salut ðŸ‘‹ ! En quoi puis-je vous aider ?",
    "hello": "Hello ! Je suis Ã  votre service.",
    "Ã§a va": "Je vais bien merci, prÃªt Ã  vous aider !",
    "bonsoir": "Bonsoir ðŸŒ™ ! PrÃªt Ã  analyser vos problÃ¨mes techniques ?"
}

class SmartChatbot:
    def __init__(self, path_to_file):
        self.df = pd.read_excel(path_to_file)
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.embeddings = self.model.encode(self.df['Question'].tolist(), convert_to_tensor=True)

    def get_response(self, user_input):
        user_input_lower = user_input.lower()

        # ðŸŽ¯ VÃ©rifie sâ€™il sâ€™agit dâ€™une salutation
        for mot in SALUTATIONS:
            if mot in user_input_lower:
                return {
                    "question_trouvÃ©e": mot,
                    "rÃ©ponse": SALUTATIONS[mot],
                    "solution": "N'hÃ©sitez pas Ã  poser une question technique.",
                    "type_anomalie": "GÃ©nÃ©ral",
                    "similaritÃ©": 1.0
                }

        # ðŸ§  Sinon, logique BERT classique
        query_embedding = self.model.encode(user_input, convert_to_tensor=True)
        scores = util.pytorch_cos_sim(query_embedding, self.embeddings)[0]
        best_idx = scores.argmax().item()
        best_match = self.df.iloc[best_idx]
        return {
            "question_trouvÃ©e": best_match["Question"],
            "rÃ©ponse": best_match["RÃ©ponse"],
            "solution": best_match["Solution"],
            "type_anomalie": best_match["Type d'anomalie"],
            "similaritÃ©": scores[best_idx].item()
        }
